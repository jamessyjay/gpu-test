apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpu-accept-daemon
spec:
  selector:
    matchLabels:
      app: gpu-accept-daemon
  template:
    metadata:
      labels:
        app: gpu-accept-daemon
    spec:
      restartPolicy: Always
      containers:
        - name: tester
          image: ghcr.io/jamessyjay/gpu-cluster-acceptance:gpu
          imagePullPolicy: Always
          resources:
            limits:
              nvidia.com/gpu: 1
          env:
            - name: QUICK
              value: "0"
            - name: VERBOSE
              value: "0"
            - name: REPORT_DIR
              value: "/app/reports"
            - name: TRAIN_SMOKE
              value: "0"
            - name: EPOCHS
              value: "1"
            - name: STEPS
              value: "10"
            - name: GPUS_PER_NODE
              value: "1"
          volumeMounts:
            - name: reports
              mountPath: /app/reports
          command: ["bash","-lc"]
          args:
            - |
              set -euo pipefail
              # ensure reports dir exists
              python - << 'PY'
              import os
              os.makedirs('/app/reports', exist_ok=True)
              PY

              # 1) DDP test via torchrun --standalone (single-node)
              GPUS=${GPUS_PER_NODE:-1}
              DDP_ARGS="--report-dir ${REPORT_DIR} --report-name ddp_tests_result.json"
              if [ "${VERBOSE}" = "1" ]; then
                DDP_ARGS="--verbose ${DDP_ARGS}"
              fi
              if [ "${TRAIN_SMOKE}" = "1" ]; then
                DDP_ARGS="--train-smoke --epochs ${EPOCHS} --steps ${STEPS} ${DDP_ARGS}"
                DDP_ARGS=$(echo "$DDP_ARGS" | sed "s/ddp_tests_result.json/ddp_training_result.json/")
              fi
              echo "Running torchrun --standalone with args: ${DDP_ARGS}"
              torchrun --standalone --nproc_per_node=${GPUS} src/ddp_tests.py ${DDP_ARGS}

              # 2) Single-node GPU tests (compute + training)
              GARGS="--report-dir ${REPORT_DIR}"
              if [ "${QUICK}" = "1" ]; then
                GARGS="--quick ${GARGS}"
              fi
              if [ "${VERBOSE}" = "1" ]; then
                GARGS="--verbose ${GARGS}"
              fi
              echo "Running gpu_tests.py with args: ${GARGS}"
              exec python src/gpu_tests.py ${GARGS}
      volumes:
        - name: reports
          emptyDir: {}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-accept-daemon-readme
data:
  HOW_TO_GET_REPORTS: |
    Each pod writes JSON to /app/reports (emptyDir). Use `kubectl cp` or `kubectl logs` to collect.
